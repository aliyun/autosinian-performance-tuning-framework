# AutoSinian MLPERF Benchmark Results
## v0.7_inference_open
This result follows the policies of mlperf v0.7 inference open division. It passed the submission checker, but it is not an official submission, thus not reviewed by MLPERF group.

We put detailed steps for replication in the result, and encourage everyone to reproduce our result. Numbers don't lie.

### detailed results
see [summary.csv](v0.7_inference_open/results/summary.csv)

### Replication
On [A100](v0.7_inference_open/measurements/alibaba_cloud_Sinian_A100/OFAnet-AutoSinian/Offline/README.md)

On [V100](v0.7_inference_open/measurements/alibaba_cloud_Sinian_V100/OFAnet-AutoSinian/Offline/README.md)

On [T4](v0.7_inference_open/measurements/alibaba_cloud_Sinian_T4/OFAnet-AutoSinian/Offline/README.md)